{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31bb8b50-1034-4960-8485-e9f7f3d632e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.20.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import random\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import requests\n",
    "import pandas_datareader as web\n",
    "\n",
    "# Date\n",
    "import datetime as dt\n",
    "from datetime import date, timedelta, datetime\n",
    "\n",
    "# EDA\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# FE\n",
    "from tsfresh import extract_features, select_features, extract_relevant_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from sklearn.inspection import permutation_importance\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import shap\n",
    "\n",
    "# Time Series - EDA and Modelling\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# Modeling and preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from prophet import Prophet\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3301d46-0d8b-4d6a-af7c-7db154c13a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What EDA & FE techniques use?\n",
    "is_anomalies = True # or False - Take into account anomalies or no?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8ad7e5e-70d0-4b31-80b0-091eb1b8f62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What type of model to use?\n",
    "is_Prophet = True   # or False - Facebook Prophet\n",
    "is_ARIMA = False     # or False - ARIMA and AutoARIMA\n",
    "is_other_ML = True  # or False - multi-factors models: trees, neural networks, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bfab239-a411-4c9d-a584-f5087804d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic building ARIMA for Time Series\n",
    "if is_ARIMA:\n",
    "    !pip install pmdarima\n",
    "    import pmdarima as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b89fba7d-91e8-4972-a9fa-fad00c2a9398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random state\n",
    "def fix_all_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "random_state = 42\n",
    "fix_all_seeds(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e49d0431-30b0-437d-9fa8-4b7c1979aa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the main parameter\n",
    "forecasting_days = 7  # forecasting_days > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7363a271-92f4-4763-9a0c-53be19827950",
   "metadata": {},
   "outputs": [
    {
     "ename": "OptionError",
     "evalue": "'Pattern matched multiple keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOptionError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_option\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_columns\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg/lib/python3.9/site-packages/pandas/_config/config.py:256\u001b[0m, in \u001b[0;36mCallableDynamicDoc.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__func__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg/lib/python3.9/site-packages/pandas/_config/config.py:149\u001b[0m, in \u001b[0;36m_set_option\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_set_option() got an unexpected keyword argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwarg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(args[::\u001b[38;5;241m2\u001b[39m], args[\u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m]):\n\u001b[0;32m--> 149\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43m_get_single_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     o \u001b[38;5;241m=\u001b[39m _get_registered_option(key)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m o \u001b[38;5;129;01mand\u001b[39;00m o\u001b[38;5;241m.\u001b[39mvalidator:\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg/lib/python3.9/site-packages/pandas/_config/config.py:116\u001b[0m, in \u001b[0;36m_get_single_key\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OptionError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such keys(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(pat)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(keys) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OptionError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPattern matched multiple keys\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    117\u001b[0m key \u001b[38;5;241m=\u001b[39m keys[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silent:\n",
      "\u001b[0;31mOptionError\u001b[0m: 'Pattern matched multiple keys'"
     ]
    }
   ],
   "source": [
    "pd.set_option('max_columns',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8117aa6-ea26-4b6a-a626-8b73654ee55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set indicator names (see dataset https://www.kaggle.com/datasets/vbmokin/wq-southern-bug-river-01052021)\n",
    "# all_indicator_names as str : 'NH4', 'BSK5', 'NO3', 'NO2', 'SO4', 'PO4', 'CL'\n",
    "target_indicator_name = 'NO3'\n",
    "feature_indicator_names = ['NH4', 'NO2', 'CL']  # if it is necessary to forecast the data, \n",
    "                                          # taking into account the data of other indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74bb0ce-189e-46d4-8e78-d110b7202495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set id of stations\n",
    "id_target_station = 14\n",
    "# all_id_station as int: 1-21 (21 - river outlet, 1 - river mouth, \n",
    "#                        stations numbering - against the flow of the river)\n",
    "id_feature_station = [15, 16]  # if it is necessary to forecast the data, \n",
    "                               # taking into account the data of other stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304e89d1-f270-4a3b-81dd-688edf1ad928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_water_data(target_indicator_name : str, \n",
    "                   id_target_station : int,  \n",
    "                   date_start : str = \"2000-01-02\", \n",
    "                   feature_indicator_names : list = [], # list of str\n",
    "                   id_feature_station : list = [],      # list of int\n",
    "                   date_end : str = \"2021-06-04\"):\n",
    "    # Get data on the water quality of the Southern Booh (or Bug) River \n",
    "    # for the given indicators (target and others, if necessary) \n",
    "    # at the given stations (target and others, if necessary) \n",
    "    # for the given dates in format \"str\" inclusive of these dates\n",
    "    \n",
    "    # Indicators names\n",
    "    all_indicator_names = feature_indicator_names + [target_indicator_name]\n",
    "    print('Selected indicator names:', all_indicator_names)\n",
    "        \n",
    "    # Information about stations\n",
    "    pd.set_option('max_colwidth',200)\n",
    "    all_id_stations = id_feature_station + [id_target_station]\n",
    "    data_about = pd.read_csv('../input/wq-southern-bug-river-01052021/PB_stations.csv', sep=';', header=0, encoding='cp1251')\n",
    "    print('All stations:')\n",
    "    display(data_about.sort_values(by=['length'], ascending=False))\n",
    "    print('\\nSelected stations:')\n",
    "    display(data_about[data_about['id'].isin(all_id_stations)])\n",
    "    \n",
    "    # Get data from given id_stations with given indicators and dates\n",
    "    data = pd.read_csv('../input/wq-southern-bug-river-01052021/PB_All_2000_2021.csv', sep=';', header=0)\n",
    "    data['ds'] = pd.to_datetime(data['date'])\n",
    "    \n",
    "    # Data sampling only for selected stations\n",
    "    df_indicator = data[['id', 'ds'] + all_indicator_names]\n",
    "    df_indicator = df_indicator[df_indicator['id'].isin(all_id_stations)].dropna().reset_index(drop=True)\n",
    "\n",
    "    # Set new cols\n",
    "    cols = []\n",
    "    for station in all_id_stations:\n",
    "        for feature in all_indicator_names:\n",
    "            cols.append(str(station) + \"_\" + feature)\n",
    "\n",
    "    df = pd.pivot_table(df_indicator, index=[\"ds\"], columns=[\"id\"], values=all_indicator_names).dropna()\n",
    "    df.columns = cols\n",
    "    df = df.reset_index(drop=False)\n",
    "        \n",
    "    # Set new target name\n",
    "    new_target_name = str(id_target_station) + \"_\" + target_indicator_name\n",
    "    \n",
    "    # Get data between given dates\n",
    "    df = df[(df['ds']>=date_start) & (df['ds']<=date_end)].reset_index(drop=True)\n",
    "    \n",
    "    return df, all_indicator_names, all_id_stations, new_target_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b07e72-2917-482c-b01b-2fdaf7542dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, all_indicator_names, all_id_stations, target_name = get_water_data(target_indicator_name, \n",
    "                                                                           id_target_station,\n",
    "                                                                           feature_indicator_names = feature_indicator_names,\n",
    "                                                                           id_feature_station=id_feature_station)\n",
    "print(f'\\nData for processing (target name - \"{target_name}\"):')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfd9702-1797-43d8-9f8b-021c1d4191a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tsfresh_features(data):\n",
    "    # Get statistic features using library TSFRESH \n",
    "    # Thanks to https://www.kaggle.com/code/vbmokin/btc-growth-forecasting-with-advanced-fe-for-ohlc\n",
    "    \n",
    "    # Extract features\n",
    "    extracted_features = extract_features(data, column_id=\"ds\", column_sort=\"ds\")\n",
    "    \n",
    "    # Drop features with NaN\n",
    "    extracted_features_clean = extracted_features.dropna(axis=1, how='all').reset_index(drop=True)\n",
    "    \n",
    "    # Drop features with constants\n",
    "    cols_std_zero  = []\n",
    "    for col in extracted_features_clean.columns:\n",
    "        if extracted_features_clean[col].std()==0:\n",
    "            cols_std_zero.append(col)\n",
    "    extracted_features_clean = extracted_features_clean.drop(columns = cols_std_zero)\n",
    "\n",
    "    extracted_features_clean['ds'] = data['ds']   # For the merging\n",
    "    \n",
    "    return extracted_features_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ab7697-e2fa-4340-a9b8-342296e139f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# FE with TSFRESH\n",
    "extracted_features_clean = get_tsfresh_features(df[['ds', target_name]])\n",
    "extracted_features_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd11a8-67e1-4f46-89a5-c7c7bf828a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c0a854-d871-4ba8-bf26-ac8441a1d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracted features by TSFRESH with cleaning\n",
    "extracted_features_clean.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2f3ad3-37e8-4a6f-98a1-82966766d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all features\n",
    "df = pd.merge(df, extracted_features_clean, how='left', on='ds')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26cd178-61fe-430c-9f91-5b0d4fba3aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cab61b-854c-4358-babb-da95adec57b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthesis dataframe with anomalous dates for Facebook Prophet\n",
    "if is_anomalies:\n",
    "    anomalous_dates = ['2014-02-09', '2013-04-04']\n",
    "    holidays_df = pd.DataFrame(columns = ['ds', 'lower_window', 'upper_window', 'prior_scale'])\n",
    "    holidays_df['ds'] = anomalous_dates\n",
    "    holidays_df['holiday'] = 'anomalous_dates'\n",
    "    holidays_df['lower_window'] = 0\n",
    "    holidays_df['upper_window'] = 0\n",
    "    holidays_df['prior_scale'] = 10\n",
    "    display(holidays_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b740dc6-ef09-40ae-92a5-68c735cd3162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_data(df, y, num_start, num_end):\n",
    "    # Cutting dataframe df and array or list for [num_start, num_end-1]        \n",
    "    df2 = df[num_start:(num_end+1)]\n",
    "    y2 = y[num_start:(num_end+1)] if y is not None else None\n",
    "    return df2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e08516f-b86f-47aa-8d3d-86cb97ff3104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_mf(df, forecasting_days, col=target_name):\n",
    "    # Get target as difference of the df[col] \n",
    "    # Returns target which is shifted for forecasting_days days in the dataframe df\n",
    "    # \"target_name\" -> \"target\" \n",
    "    df['target'] = df[target_name].shift(-forecasting_days)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bb6045-8079-447b-9221-0fb7396d8c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_test_ts(df, forecasting_days, target=target_name):\n",
    "    # Get training, validation and test datasets with target for Time Series models\n",
    "    \n",
    "    # Data prepairing\n",
    "    df = df.dropna(how=\"any\").reset_index(drop=True)\n",
    "    df = df[['ds', target_name]]\n",
    "    df.columns = ['ds', 'y']        \n",
    "    y = None\n",
    "\n",
    "#     \n",
    "    \n",
    "    N = len(df)\n",
    "    train, _ = cut_data(df, y, 0, N-2*forecasting_days-1)\n",
    "    valid, _ = cut_data(df, y, N-2*forecasting_days, N-forecasting_days-1)\n",
    "    test, _ = cut_data(df, y, N-forecasting_days, N)\n",
    "    \n",
    "    # Train+valid - for optimal model training\n",
    "    train_valid = pd.concat([train, valid])\n",
    "\n",
    "    print(f'Origin dataset has {len(df)} rows and {len(df.columns)} features')\n",
    "    print(f'Get training dataset with {len(train)} rows')\n",
    "    print(f'Get validation dataset with {len(valid)} rows')\n",
    "    print(f'Get test dataset with {len(test)} rows')\n",
    "    \n",
    "    return train, valid, test, train_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bf539b-5768-49a8-8b85-c1b3cc943bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(type_score, list_true, list_pred):\n",
    "    # Calculation score with type=type_score for list_true and list_pred \n",
    "    if type_score=='r2_score':\n",
    "        score = r2_score(list_true, list_pred)\n",
    "    elif type_score=='rmse':\n",
    "        score = mean_squared_error(list_true, list_pred, squared=False)\n",
    "    elif type_score=='mape':\n",
    "        score = mean_absolute_percentage_error(list_true, list_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba12068-c9ad-4be8-9a03-db8502ac13dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_add_metrics(result, n, y_true, y_pred):\n",
    "    # Calculation and addition metrics into dataframe result[n,:]\n",
    "    \n",
    "    result.loc[n,'r2_score'] = calc_metrics('r2_score', y_true, y_pred)\n",
    "    result.loc[n,'rmse'] = calc_metrics('rmse', y_true, y_pred)      # in coins\n",
    "    result.loc[n,'mape'] = 100*calc_metrics('mape', y_true, y_pred)  # in %\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e793b678-bccb-4175-87da-af44bd2c1f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results of all models\n",
    "result = pd.DataFrame(columns = ['name_model', 'type_data', 'r2_score', 'rmse', 'mape', 'params', 'ypred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44e48fc-5571-4e5f-bc03-627b58b931f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get datasets\n",
    "if is_Prophet:\n",
    "    train_ts, valid_ts, test_ts, train_valid_ts = get_train_valid_test_ts(df.copy(), forecasting_days, target=target_name)\n",
    "    \n",
    "    if not is_anomalies:\n",
    "        holidays_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66adf3f9-59aa-47b8-8188-5fc96d763fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prophet_modeling(result, \n",
    "                     indicator, \n",
    "                     train, \n",
    "                     test, \n",
    "                     holidays_df, \n",
    "                     period_days,\n",
    "                     fourier_order_seasonality,\n",
    "                     forecasting_period,\n",
    "                     name_model,\n",
    "                     type_data):\n",
    "    # Performs FB Prophet model training for given train dataset, holidays_df and seasonality_mode\n",
    "    # Performs forecasting with period by this model, visualization and error estimation\n",
    "    # df - dataframe with real data in the forecasting_period\n",
    "    # can be such combinations of parameters: train=train, test=valid or train=train_valid, test=test\n",
    "    # Save results into dataframe result\n",
    "    \n",
    "    # Build Prophet model with parameters and structure \n",
    "    model = Prophet(daily_seasonality=False, \n",
    "                    weekly_seasonality=False, \n",
    "                    yearly_seasonality=False, \n",
    "                    changepoint_range=1, \n",
    "                    changepoint_prior_scale = 0.5, \n",
    "                    holidays=holidays_df, \n",
    "                    seasonality_mode = 'multiplicative'\n",
    "                   )\n",
    "    model.add_seasonality(name='seasonality', period=period_days, \n",
    "                          fourier_order=fourier_order_seasonality, \n",
    "                          mode = 'multiplicative', prior_scale = 0.5)\n",
    "    # Training model for df\n",
    "    model.fit(train)\n",
    "    \n",
    "    # Make a forecast\n",
    "    future = model.make_future_dataframe(periods = forecasting_period)\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    # Draw plot of the values with forecasting data\n",
    "    figure = model.plot(forecast, xlabel = 'ds', ylabel = f\"{name_model} for {indicator}\")\n",
    "    \n",
    "    # Draw plot with the components (trend and seasonalities) of the forecasts\n",
    "    figure_component = model.plot_components(forecast)\n",
    "    \n",
    "    # Ouput the prediction for the next time on forecasted_days\n",
    "    #forecast[['yhat_lower', 'yhat', 'yhat_upper']] = forecast[['yhat_lower', 'yhat', 'yhat_upper']].round(1)\n",
    "    #forecast[['ds', 'yhat_lower', 'yhat', 'yhat_upper']].tail(forecasting_period)\n",
    "    \n",
    "    # Forecasting data by the model\n",
    "    ypred = forecast['yhat'][-forecasting_period:]\n",
    "    #print(ypred)\n",
    "    # Save results\n",
    "    n = len(result)\n",
    "    result.loc[n,'name_model'] = f\"Prophet_{name_model}\"\n",
    "    result.loc[n,'type_data'] = type_data\n",
    "    result.at[n,'params'] = [period_days]+[fourier_order_seasonality]\n",
    "    result.at[n,'ypred'] = ypred\n",
    "    #result = result_add_metrics(result, n, test['y'], y_pred)\n",
    "    \n",
    "    return result, ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd5f790-1046-45c1-b958-b8d38dcaaef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Models tuning\n",
    "if is_Prophet:\n",
    "    for period_days in [2, 3, 5, 10]:\n",
    "        for fourier_order_seasonality in [3, 12]:\n",
    "            result, _ = prophet_modeling(result, \n",
    "                                         target_indicator_name, \n",
    "                                         train_ts, \n",
    "                                         valid_ts, \n",
    "                                         holidays_df, \n",
    "                                         period_days,\n",
    "                                         fourier_order_seasonality,\n",
    "                                         forecasting_days,\n",
    "                                         f'{period_days}_days_{fourier_order_seasonality}_order',\n",
    "                                         'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7049f7bb-aed3-4b77-b178-e114b2c25435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get datasets\n",
    "if is_ARIMA:\n",
    "    train_ts, valid_ts, test_ts, train_valid_ts = get_train_valid_test_ts(df.copy(), forecasting_days, target=target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d53028-fa84-4081-9299-38fc03a02900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acf_pacf_draw(df, lag_num=40, acf=True, pacf=True, title=\"\", ylim=1):\n",
    "    # Draw plots named title with ACF and PACF for dataframe df\n",
    "    \n",
    "    num_plots = 1+int(acf)+int(pacf)\n",
    "    fig, ax = plt.subplots(1,num_plots,figsize=(12,6))\n",
    "    # 'Original Series'\n",
    "    ax[0].plot(df.values.squeeze())\n",
    "    \n",
    "    if acf:\n",
    "        # ACF drawing\n",
    "        plot_acf(df.values.squeeze(), lags=lag_num, ax=ax[1])\n",
    "        ax[1].set(ylim=(-ylim, ylim))\n",
    "        \n",
    "        if pacf:\n",
    "            # PACF drawing\n",
    "            plot_pacf(df.values.squeeze(), lags=lag_num, ax=ax[2])\n",
    "            ax[2].set(ylim=(-ylim, ylim))\n",
    "        \n",
    "    elif pacf:\n",
    "        # PACF drawing\n",
    "        plot_pacf(df.values.squeeze(), lags=lag_num, ax=ax[1])\n",
    "        ax[1].set(ylim=(-ylim, ylim))\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44225a2a-efd7-44fa-9b93-c330a1bdd475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima_fit(df, col, order=(1,1,1)):\n",
    "    # ARIMA model fitting for series df[col]\n",
    "    \n",
    "    model = sm.tsa.arima.ARIMA(df[col].values.squeeze(), order=order)\n",
    "    model = model.fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e3667-fbc2-4132-8fa0-c472da2a1a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_residual_errors(model):\n",
    "    # Calculation and drawing the plot residual errors for ARIMA model\n",
    "    residuals = pd.DataFrame(model.resid)\n",
    "    fig, ax = plt.subplots(1,2, figsize=(12,6))\n",
    "    residuals.plot(title=\"Residuals\", ax=ax[0])\n",
    "    residuals.plot(kind='kde', title='Density', ax=ax[1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61772fb9-3a17-4852-806e-cdf36161861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima_forecasting(result, model, params, name_model, df, type_data):\n",
    "    # Data df (validation or test) forecasting on the num days by the model \n",
    "    # with params and save metrics to result \n",
    "    \n",
    "    ypred = model.forecast(steps=len(df))\n",
    "    \n",
    "    n = len(result)\n",
    "    result.loc[n,'name_model'] = name_model\n",
    "    result.loc[n,'type_data'] = type_data\n",
    "    result.at[n,'params'] = params\n",
    "    result.at[n,'ypred'] = ypred\n",
    "    #result = result_add_metrics(result, n, df['y'], y_pred)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3143714-37a6-4f35-89cf-e14401a1b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if is_ARIMA:\n",
    "    # Automatic tuning of the ARIMA model \n",
    "    model_auto = pm.auto_arima(train_ts['y'].values, \n",
    "                               start_p=4,        # start p\n",
    "                               start_q=4,        # start q\n",
    "                               test='adf',       # use adftest to find optimal 'd'\n",
    "                               max_p=5, max_q=5, # maximum p and q\n",
    "                               m=1,              # frequency of series (1 - No Seasonality)\n",
    "                               d=None,           # let model determine 'd'\n",
    "                               seasonal=False,   # No Seasonality\n",
    "                               start_P=0,        \n",
    "                               D=0, \n",
    "                               start_Q=0,\n",
    "                               trace=True,\n",
    "                               error_action='ignore',  \n",
    "                               suppress_warnings=False, \n",
    "                               stepwise=True     # use the stepwise algorithm outlined in Hyndman and Khandakar (2008) \n",
    "                                                 # to identify the optimal model parameters. \n",
    "                                                 # The stepwise algorithm can be significantly faster than fitting all \n",
    "                                                 # hyper-parameter combinations and is less likely to over-fit the model\n",
    "                              )\n",
    "\n",
    "    print(model_auto.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e170c856-c54e-47c6-9d3c-3cd8f249ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_ARIMA:\n",
    "    # Get orders of the best model from AutoARIMA\n",
    "    arima_orders_best = list(model_auto.get_params().get('order'))\n",
    "    print(f\"Optimal parameters are {arima_orders_best}\")\n",
    "    model_auto = arima_fit(train_ts, 'y', order=(arima_orders_best[0],arima_orders_best[1],arima_orders_best[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e96c2d-0885-42c6-a6af-d4eb3c0b56b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_ARIMA:\n",
    "    # Best model from AutoARIMA\n",
    "    fig = model_auto.plot_diagnostics(figsize=(12,10))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2559ef6-79ac-4d05-80a9-54c26959b849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ae4837-174f-42cc-9f55-0a406ef2541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c50252-1fa8-4f2b-98aa-d6240c1d92a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get datasets\n",
    "if is_other_ML:\n",
    "    df2 = get_target_mf(df, forecasting_days, col=target_name)\n",
    "    train_mf, ytrain_mf, valid_mf, yvalid_mf, test_mf, ytest_mf, train_valid_mf, y_train_valid_mf, starting_point = \\\n",
    "                                    get_train_valid_test_mf(df2.copy(), forecasting_days, target='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50297fff-e608-41b5-af5f-f730f691941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_other_ML:\n",
    "    # Set parameters of models\n",
    "    models = pd.DataFrame(columns = ['name', 'model', 'param_grid'])\n",
    "\n",
    "    # Linear Regression\n",
    "    n = len(models)\n",
    "    models.loc[n, 'name'] = 'Linear Regression'\n",
    "    models.at[n, 'model'] = LinearRegression()\n",
    "    models.at[n, 'param_grid'] = {'fit_intercept' : [True, False]}\n",
    "\n",
    "                                   \n",
    "    # Support Vector Machines\n",
    "    n = len(models)\n",
    "    models.loc[n, 'name'] = 'Support Vector Machines'\n",
    "    models.at[n, 'model'] = SVR()\n",
    "    models.at[n, 'param_grid'] = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                                  'C': np.linspace(1, 15, 15),\n",
    "                                  'tol': [1e-3, 1e-4]\n",
    "                                 }\n",
    "\n",
    "        # Random Forest Classifier\n",
    "    n = len(models)\n",
    "    models.loc[n, 'name'] = 'Random Forest Regressor'\n",
    "    models.at[n, 'model'] = RandomForestRegressor()\n",
    "    models.at[n, 'param_grid'] = {'n_estimators': [40, 50, 60, 80], \n",
    "                                  'min_samples_split': [30, 40, 50, 60], \n",
    "                                  'min_samples_leaf': [10, 12, 15, 20, 50],\n",
    "                                  'max_features': ['auto'], \n",
    "                                  'max_depth': [3, 4, 5, 6]                   \n",
    "                                 }\n",
    "\n",
    "    # Bagging Classifier\n",
    "    n = len(models)\n",
    "    models.loc[n, 'name'] = 'Bagging Regressor'\n",
    "    models.at[n, 'model'] = BaggingRegressor()\n",
    "    models.at[n, 'param_grid'] = {'max_features': np.linspace(0.05, 0.8, 1),\n",
    "                                  'n_estimators': [3, 4, 5, 6],\n",
    "                                  'warm_start' : [False]\n",
    "                                 }\n",
    "\n",
    "    # XGB Classifier\n",
    "    n = len(models)\n",
    "    models.loc[n, 'name'] = 'XGB Regressor'\n",
    "    models.at[n, 'model'] = xgb.XGBRegressor()\n",
    "    models.at[n, 'param_grid'] = {'n_estimators': [50, 70, 90], \n",
    "                                  'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "                                  'max_depth': [3, 4, 5]\n",
    "                                 }\n",
    "\n",
    "    \n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1a05b-6042-4a14-8c12-d212615d7a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(result, models, train_features, valid_features, train_labels, valid_labels):    \n",
    "    # Models training and data prediction for all models from DataFrame models\n",
    "    # Saving results for validation dataset into dataframe result\n",
    "    \n",
    "    def calc_add_score(res, n, type_score, list_true, list_pred, feature_end):\n",
    "        # Calculation score with type=type_score for list_true and list_pred \n",
    "        # Adding score into res.loc[n,...]\n",
    "        res.loc[i, type_score + feature_end] = calc_metrics(type_score, list_true, list_pred)\n",
    "        return res\n",
    "    \n",
    "    # Results\n",
    "    model_all = []\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        # Training\n",
    "        print(f\"Tuning model '{models.loc[i, 'name']}'\")\n",
    "        model = GridSearchCV(models.at[i, 'model'], models.at[i, 'param_grid'])\n",
    "        model.fit(train_features, train_labels)\n",
    "        model_all.append(model)\n",
    "        print(f\"Best parameters: {model.best_params_}\\n\")\n",
    "        \n",
    "        # Prediction\n",
    "        ypred = model.predict(valid_features)\n",
    "        \n",
    "        # Scoring and saving results into the main dataframe result\n",
    "        n = len(result)\n",
    "        result.loc[n,'name_model'] = f\"{models.loc[i, 'name']}\"\n",
    "        result.loc[n,'type_data'] = \"valid\"\n",
    "        result.at[n,'params'] = model.best_params_\n",
    "        result.at[n,'ypred'] = ypred\n",
    "        #result = result_add_metrics(result, n, valid_labels, valid_pred)\n",
    "        \n",
    "    return result, model_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd7303-8cd4-43b4-aeac-8348f6ae5e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if is_other_ML:\n",
    "    # Models tuning and the forecasting\n",
    "    result, model_all = model_prediction(result, models, train_mf, valid_mf, ytrain_mf, yvalid_mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2c396c-1b32-4f54-9412-cd92500030b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recovery_prediction(y, starting_point):\n",
    "    # Recovering prediction of multi-factors model for shifted col to col in the dataframe df\n",
    "    # y has type np.array\n",
    "    # starting_point is dictionary with start values for the recovering data\n",
    "    # Returns y (np.array) with recovering data\n",
    "    \n",
    "    return np.insert(y, 0, starting_point).cumsum()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f8da5-4894-4933-b8b9-3933338af84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_recover_and_metrics(result, df_ts, type_data, start_points):\n",
    "    # Recovering prediction: from shifted_Close to Close\n",
    "    # Calculation metrics for recovering ypred forecasting for all models in result\n",
    "    # ypred real is from df_ts['y']\n",
    "    # start points value for the recovering is from dictionary start_points\n",
    "    # type_data = 'valid' or 'test'\n",
    "\n",
    "    for i in range(len(result)):\n",
    "        if (result.loc[i, 'type_data']==type_data) and (result.loc[i, 'mape'] is np.nan):\n",
    "            ypred = result.loc[i, 'ypred']\n",
    "\n",
    "            # Recovering ypred for multi-factors models\n",
    "            if not (str(result.loc[i, 'type_model']) in ['Prophet', 'ARIMA']):\n",
    "                # Multi-factors model\n",
    "                # Get start points value for the recovering\n",
    "                start_point_value = start_points['valid_start_point'] if type_data=='valid' else start_points['test_start_point']\n",
    "                # Recovering prediction\n",
    "                ypred = recovery_prediction(ypred, start_point_value)            \n",
    "\n",
    "            # Calculation metrics\n",
    "            result = result_add_metrics(result, i, df_ts['y'], ypred)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe62a7-d9b6-4886-8e9e-e1209627ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispay and save all results for validation dataset\n",
    "if len(result) > 0:\n",
    "    \n",
    "    # Get type of each model\n",
    "    result['type_model'] = result['name_model'].str.split('_').str[0]\n",
    "\n",
    "    # Calculation metrics for recovering prediction ypred for validation dataset by all models \n",
    "    result = result_recover_and_metrics(result, valid_ts, 'valid', starting_point)\n",
    "    display(result[['name_model', 'type_data', 'r2_score', 'rmse', 'mape']].sort_values(by=['type_data', 'mape', 'rmse'], ascending=True))\n",
    "    \n",
    "    # Save results\n",
    "    num_models = len(result[result['type_data']=='valid']['name_model'].unique().tolist())\n",
    "    print(f\"Number of models built - {num_models}\")\n",
    "    result.to_csv(f'result_of_{num_models}_models_for_forecasting_days_{forecasting_days}.csv')\n",
    "else: \n",
    "    print('There are no tuned models!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b777d7bf-8f5b-4feb-b6dc-242f686236c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_opt(name_model, params):\n",
    "    # Model tuning for the name_model\n",
    "    \n",
    "    print(name_model)\n",
    "    if name_model=='Linear Regression':\n",
    "        model = LinearRegression(**params)\n",
    "        \n",
    "              \n",
    "    elif name_model=='Support Vector Machines':\n",
    "        model = SVR(**params)\n",
    "        \n",
    "            \n",
    "    elif name_model=='Random Forest Regressor':\n",
    "        model = RandomForestRegressor(**params)\n",
    "        \n",
    "    elif name_model=='Bagging Regressor':\n",
    "        model = BaggingRegressor(**params)\n",
    "    \n",
    "            \n",
    "    elif name_model=='XGB Regressor':\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        \n",
    "    else: model = None\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e52f456-d713-4538-9509-5b1a3709ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_optimal_model(result, main_metrics):\n",
    "    # Get parameters of the optimal model from dataframe result by main_metrics\n",
    "\n",
    "    # Set the data type to float (just in case)\n",
    "    result[main_metrics] = result[main_metrics].astype('float')\n",
    "    \n",
    "    # Choose the optimal model\n",
    "    opt_result = result[result['type_data']=='valid'].reset_index(drop=True)\n",
    "    if main_metrics=='r2_score':\n",
    "        opt_model = opt_result.nlargest(1, main_metrics)\n",
    "    else:\n",
    "        # 'mape' or 'rmse'\n",
    "        opt_model = opt_result.nsmallest(1, main_metrics)\n",
    "    display(opt_model[['name_model', 'r2_score', 'rmse', 'mape', 'params']])\n",
    "\n",
    "    # Get parameters of the optimal model\n",
    "    opt_name_model = opt_model['name_model'].tolist()[0]\n",
    "    opt_type_model = opt_model['type_model'].tolist()[0]\n",
    "    opt_params_model = opt_model['params'].tolist()[0]\n",
    "    print(f'Optimal model by metrics \"{main_metrics}\" is \"{opt_name_model}\" with type \"{opt_type_model}\" parameters {opt_params_model}')\n",
    "    \n",
    "    return opt_name_model, opt_type_model, opt_params_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d0d77-456b-4cc6-a3ae-848337d47ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_forecasting(result, df, y, test, ytest,  \n",
    "                               name_model, type_model, params, type_test='1'):\n",
    "    # Model training for df and y\n",
    "    # Forecasting ypred\n",
    "    # type_model = 'Prophet' or \"ARIMA\" or 'Other ML'\n",
    "    # type_test = '1' (with find optimal parameters by GridSearchCV) \n",
    "    # type_test = '2' (with optimal parameters - without GridSearchCV)\n",
    "    # return params and metrics in the dataframe result\n",
    "    \n",
    "    if type_model=='Prophet':    \n",
    "        season_days_optimal = params[0]\n",
    "        fourier_order_seasonality_optimal = params[1]\n",
    "        model_opt = None\n",
    "        _, ypred = prophet_modeling(result, \n",
    "                                    target_indicator_name, \n",
    "                                    df, \n",
    "                                    test, \n",
    "                                    holidays_df, \n",
    "                                    season_days_optimal,\n",
    "                                    fourier_order_seasonality_optimal,\n",
    "                                    forecasting_days,\n",
    "                                    f'{type_model}_optimal',\n",
    "                                    'test')        \n",
    "    elif type_model=='ARIMA':\n",
    "        season_days_optimal = params[0]\n",
    "        fourier_order_seasonality_optimal = params[1]        \n",
    "        model_opt = None\n",
    "        \n",
    "        # Training ARIMA optimal model for training+valid dataset\n",
    "        df['y'] = y\n",
    "        model_opt = arima_fit(df, 'y', order=(params[0],params[1],params[2]))        \n",
    "\n",
    "        # Model diagnostics\n",
    "        fig = model_opt.plot_diagnostics(figsize=(12,10))\n",
    "        plt.show()\n",
    "\n",
    "        # Plot residual errors\n",
    "        get_residual_errors(model_opt)\n",
    "\n",
    "        # Test forecasting and save result\n",
    "        ypred = model_opt.forecast(steps=len(test))        \n",
    "\n",
    "    else:\n",
    "        # Other ML model\n",
    "        # Training ML optimal model for training+valid dataset\n",
    "        print(f\"Tuning model '{name_model}'\")\n",
    "        models_opt_number = models[models['name']==name_model].index.tolist()[0]\n",
    "        #print(f\"Model - {models.at[models_opt_number,'model']} with parameters {params}\")\n",
    "        if type_test=='1':\n",
    "            model_opt = GridSearchCV(models.at[models_opt_number,'model'], models.at[models_opt_number,'param_grid'])\n",
    "        else:\n",
    "            # type_test=='2'\n",
    "            model_opt = get_model_opt(models.at[models_opt_number,'name'], params)\n",
    "        model_opt.fit(df, y)\n",
    "        \n",
    "        # Forecasting\n",
    "        ypred = model_opt.predict(test)\n",
    "\n",
    "        \n",
    "    # Scoring and saving results into the dataframe result\n",
    "    n = len(result)-1\n",
    "    result.loc[n,'name_model'] = f\"{type_model}_optimal\"\n",
    "    result.loc[n,'type_data'] = \"test\"\n",
    "    result.loc[n,'type_model'] = type_model\n",
    "    result.at[n,'params'] = params\n",
    "    result.at[n,'ypred'] = ypred\n",
    "    #result = result_add_metrics(result, n, ytest, ypred)\n",
    "    \n",
    "    return result, model_opt, ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d456dba-665a-45f2-bb2b-16feae4638a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_model_and_forecasting(result, main_metrics, start_points):\n",
    "    # Choosion the optimal model from dataframe result by main_metrics\n",
    "    # Tuning optimal model for big dataset train+valid \n",
    "    # Test forecasting and drawing it\n",
    "    # Returns the optimal model and it's name\n",
    "\n",
    "    \n",
    "    if len(result) > 0:\n",
    "        # Get parameters of the optimal model from dataframe result by main_metrics\n",
    "        opt_name_model, opt_type_model, opt_params_model = get_params_optimal_model(result, \n",
    "                                                                                    main_metrics)\n",
    "        # Set datasets for the final tuning and testing by optimal model\n",
    "        if (opt_type_model=='Prophet') or (opt_type_model=='ARIMA'):\n",
    "            train_valid = train_valid_ts.copy()\n",
    "            y_train_valid = train_valid_ts['y'].copy()\n",
    "            test = test_ts.copy()\n",
    "            ytest = test_ts['y'].copy()\n",
    "            \n",
    "        else:\n",
    "            # Multi-factors ML models\n",
    "            train_valid = train_valid_mf.copy()\n",
    "            y_train_valid = y_train_valid_mf.copy()\n",
    "            test = test_mf.copy()\n",
    "            ytest = ytest_mf.copy()\n",
    "    \n",
    "        # Optimal model training for train+valid and test forecasting\n",
    "        result, model_opt, ypred = model_training_forecasting(result, train_valid, y_train_valid,\n",
    "                                                              test, ytest,\n",
    "                                                              opt_name_model, opt_type_model, \n",
    "                                                              opt_params_model, '1')\n",
    "        \n",
    "        # Calculation metrics for recovering prediction ypred for test dataset by the optimal model\n",
    "        result = result_recover_and_metrics(result, test_ts, 'test', start_points)\n",
    "        \n",
    "        # Drawing plot for prediction for the test data \n",
    "        if not ((opt_type_model=='Prophet') or (opt_type_model=='ARIMA')):\n",
    "            # Recovery values target_name\n",
    "            ytest_plot = recovery_prediction(ytest.values, start_points['test_start_point'])\n",
    "            ypred_plot = recovery_prediction(ypred, start_points['test_start_point'])\n",
    "        else:\n",
    "            ytest_plot = ytest.copy()\n",
    "            ypred_plot = ypred.copy()\n",
    "            \n",
    "        # Drawing \n",
    "        plt.figure(figsize=(12,8))\n",
    "        x = np.arange(len(ytest_plot))\n",
    "        plt.scatter(x, ytest_plot, label = \"Target test data\", color = 'g', s=100)\n",
    "        plt.scatter(x, ypred_plot, label = f\"{opt_name_model} forecasting\", color = 'r', s=50)\n",
    "        plt.title(f'Forecasting of test data using the \"{opt_name_model}\" model, which is optimal for \"{main_metrics}\" metrics')\n",
    "        plt.ylim(0)\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        return opt_name_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f6bfa1-f2dd-4e20-97fb-50d94e15fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal model by different metrics\n",
    "if len(result) > 0:\n",
    "    for valid_metrics in ['r2_score', 'rmse', 'mape']:\n",
    "        get_optimal_model_and_forecasting(result, valid_metrics, starting_point)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626116fd-36fe-4199-b099-d3093d3e8c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training ML optimal model for training+valid dataset\n",
    "# Get parameters of the optimal model from dataframe result (without Time Series models) by main_metrics\n",
    "if is_other_ML:\n",
    "    main_metrics = 'r2_score'\n",
    "    if (len(result) > 0) and (len(models) > 0):\n",
    "        result_nonTS = result[(result['type_model']!='Prophet') & (result['type_model']!='ARIMA')].reset_index(drop=True)\n",
    "        opt_name_model2, opt_type_model2, opt_params_model2 = get_params_optimal_model(result_nonTS, \n",
    "                                                                                main_metrics)\n",
    "\n",
    "        result, model_opt, ypred = model_training_forecasting(result, \n",
    "                                                              train_valid_mf, \n",
    "                                                              y_train_valid_mf,\n",
    "                                                              test_mf, \n",
    "                                                              ytest_mf,\n",
    "                                                              opt_name_model2, \n",
    "                                                              opt_type_model2, \n",
    "                                                              opt_params_model2, \n",
    "                                                              '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1263b05-830d-4734-b3a0-fc8a54e42d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All features names\n",
    "if is_other_ML:\n",
    "    coeff = pd.DataFrame(train_valid_mf.columns)\n",
    "    coeff.columns = ['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26db457-6c93-4739-af1e-577a94eb12e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fi_coeff(coeff, col, list_new_fi_coeff=None, df_new_fi_coeff=None):\n",
    "    # Adds new importance of features as feature col\n",
    "    # from list list_new_fi_coeff or dataframe df_new_fi_coeff\n",
    "    # to the resulting dataframe coeff with feature names \n",
    "    # Missed importance values are replaced by zero\n",
    "    \n",
    "    if list_new_fi_coeff is not None:\n",
    "        df_new_fi_coeff = coeff[['feature']].copy()\n",
    "        df_new_fi_coeff[\"score\"] = pd.Series(list_new_fi_coeff)\n",
    "    \n",
    "    if df_new_fi_coeff is not None:\n",
    "        # Rename df_new_fi_coeff\n",
    "        df_new_fi_coeff.columns = ['feature', 'score']   # to the plot drawing\n",
    "        df_new_fi_coeff[col] = df_new_fi_coeff['score']  # to the merging and saving\n",
    "        \n",
    "        # Merging dataframes - coeff of all features with new_fi_coeff\n",
    "        coeff = coeff.merge(df_new_fi_coeff[['feature', col]], on='feature', how='left').fillna(0)\n",
    "        \n",
    "        is_score = True\n",
    "    else:\n",
    "        print(f'Data is absent fol {col}')\n",
    "        is_score = False\n",
    "        coeff = None\n",
    "    \n",
    "    return coeff, df_new_fi_coeff, is_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8394727-d191-436c-91b6-8af96c8f326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance diagram with SHAP\n",
    "if is_other_ML:\n",
    "    if (len(result) > 0) and (len(models) > 0):\n",
    "        print('Feature importance diagram with SHAP:')\n",
    "        try:\n",
    "            # Trees\n",
    "            explainer = shap.TreeExplainer(model_opt)\n",
    "            shap_values = explainer.shap_values(test_mf)\n",
    "            shap.summary_plot(shap_values, test_mf, plot_type=\"bar\", feature_names=coeff['feature'].tolist())\n",
    "            shap.summary_plot(shap_values, test_mf)\n",
    "\n",
    "            # Save permutation feature importance values\n",
    "            coeff, _, is_SHAP_successfully = add_fi_coeff(coeff, 'shap_fi_score', shap_values)\n",
    "        except: \n",
    "            try:\n",
    "                # Other types of models\n",
    "                explainer = shap.KernelExplainer(model_opt.predict, train_valid_mf)\n",
    "                shap_values = explainer.shap_values(test_mf)\n",
    "\n",
    "                # Plot drawing\n",
    "                shap.summary_plot(shap_values, test_mf, plot_type=\"bar\", feature_names=coeff['feature'].tolist())\n",
    "                shap.summary_plot(shap_values, test_mf)\n",
    "\n",
    "                # Get feature importance values from shap_values format\n",
    "                # Thanks to https://stackoverflow.com/a/69523421/12301574\n",
    "                shap_values_all = pd.DataFrame(shap_values, columns = test_mf.columns)\n",
    "                vals = np.abs(shap_values_all.values).mean(0)\n",
    "                shap_importance = pd.DataFrame(list(zip(test_mf.columns, vals)),\n",
    "                                                  columns=['feature','score'])            \n",
    "\n",
    "                # Saving feature importance values\n",
    "                coeff, _, is_SHAP_successfully = add_fi_coeff(coeff, 'shap_fi_score', None, shap_importance)            \n",
    "\n",
    "            except: \n",
    "                is_SHAP_successfully = False\n",
    "\n",
    "        if not is_SHAP_successfully:\n",
    "            print('Feature importance diagram for this optimal model is not supported in SHAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f279ded-819c-4dc7-a970-21369ae6df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force plot - Feature importance diagram with SHAP for the certaion row in test_mf\n",
    "if is_other_ML:\n",
    "    if (len(result) > 0) and (len(models) > 0):\n",
    "        row_number_in_test_mf = 0\n",
    "        print('Feature importance diagram as the Force plot with SHAP:')\n",
    "        if is_SHAP_successfully:\n",
    "            shap.initjs()\n",
    "            shap.force_plot(explainer.expected_value, shap_values[0,:], \n",
    "                            test_mf.loc[test_mf.index.tolist()[row_number_in_test_mf],:],\n",
    "                            feature_names=coeff['feature'].tolist(),\n",
    "                            matplotlib=True, show=False)\n",
    "            plt.savefig('force_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50ffcd2-c0fd-486b-a8ad-3c0529dcecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation and drawing the feature importance diagrams\n",
    "if is_other_ML:\n",
    "    if (len(result) > 0) and (len(models) > 0):\n",
    "\n",
    "        # Coefficients\n",
    "        if opt_name_model2=='XGB Regressor':\n",
    "            print('Feature importance diagram')\n",
    "            # Coef. of the feature with nonzero importance\n",
    "            xgb_coeff = pd.DataFrame.from_dict(model_opt.get_booster().get_score(importance_type='weight'), orient='index').reset_index(drop=False)\n",
    "            coeff, _, is_score = add_fi_coeff(coeff, 'xgb_fi_coeff', None, xgb_coeff)\n",
    "\n",
    "            # With the library xgboost\n",
    "            fig =  plt.figure(figsize = (15,15))\n",
    "            axes = fig.add_subplot(111)\n",
    "            xgb.plot_importance(model_opt,ax = axes,height = 0.5)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "        else:\n",
    "            # With the library sklearn\n",
    "            try:\n",
    "                coef_model = model_opt.coef_\n",
    "                coeff, coeff_new, is_score = add_fi_coeff(coeff, 'lr_fi_score', coef_model)\n",
    "            except:\n",
    "                try:\n",
    "                    coef_model = feature_importances_\n",
    "                    coeff, coeff_new, is_score = add_fi_coeff(coeff, 'model_fi_score', coef_model)\n",
    "                except: \n",
    "                    print('The importance of the feature could not be obtained')\n",
    "                    is_score = False\n",
    "\n",
    "            if is_score:\n",
    "                # Plot drawing\n",
    "                coeff_non_zero = coeff_new[coeff_new['score']>0]\n",
    "                plt.figure(figsize=(12, int(len(coeff_non_zero)*0.4)))\n",
    "                coeff_non_zero = coeff_non_zero.sort_values(by='score', ascending=True)\n",
    "                plt.barh(coeff_non_zero[\"feature\"], coeff_non_zero[\"score\"])\n",
    "                plt.title(\"Feature importance diagram\")\n",
    "                plt.axvline(x=0, color=\".5\")\n",
    "                plt.xlabel(\"Coefficient values\")\n",
    "                plt.subplots_adjust(left=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9738687f-6641-4df7-b507-03703a986416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation feature importance diagram\n",
    "if is_other_ML:\n",
    "    if (len(result) > 0) and (len(models) > 0):\n",
    "        try:\n",
    "            perm_importance = permutation_importance(model_opt, test_mf, ytest_mf)\n",
    "\n",
    "            # Save permutation feature importance values\n",
    "            coef_model = perm_importance.importances_mean\n",
    "            coeff, coeff_new, is_score = add_fi_coeff(coeff, 'perm_fi_score', coef_model)\n",
    "\n",
    "            print('Permutation feature importance diagram:') \n",
    "            coeff_non_zero = coeff_new[coeff_new['score'].abs()>1e-4]\n",
    "            coeff_non_zero = coeff_non_zero.sort_values(by='score', ascending=True)\n",
    "            plt.figure(figsize=(12, int(len(coeff_non_zero)*0.4)))\n",
    "            plt.barh(coeff_non_zero[\"feature\"], coeff_non_zero[\"score\"])\n",
    "            plt.xlabel(\"Permutation Importance\")\n",
    "            plt.show()\n",
    "            is_perm_importance = True\n",
    "        except: print('Permutation feature importance diagram for this optimal model is not supported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79082658-8749-466c-9aeb-9cfe864c417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and saving features importance values\n",
    "if is_other_ML:\n",
    "    if coeff.isna().sum().sum()==0:\n",
    "        print('Feature importance values:')\n",
    "        fi_cols = coeff.columns.tolist()[1:]\n",
    "        if len(fi_cols) > 0:\n",
    "            coeff = coeff.sort_values(by=fi_cols, ascending=False)\n",
    "            display(coeff)\n",
    "        coeff.to_csv(f'feature_importance_for_optimal_model_{opt_name_model2}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d135ca-c08d-40d2-ad11-e56158ecedc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
